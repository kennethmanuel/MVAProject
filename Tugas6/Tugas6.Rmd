---
title: "Salespeople-data"
author: "Kenneth Manuel"
date: "3/27/2021"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{R message=FALSE, warning=FALSE, include=FALSE}
library("tidyverse")
library("readxl")
library("NbClust")
library("factoextra")
library("MASS")
library("caret")
```

```{r}
data <- read_excel('Salespeople-data.xlsx')
head(data)
```
# Menentukan keputusan berapa kluster yang akan digunakan

```{r}
fviz_nbclust(data, kmeans, method = "wss") +
    geom_vline(xintercept = 2 , linetype = 2)+
  labs(subtitle = "Elbow method")

fviz_nbclust(data, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

fviz_nbclust(data, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")
```

Terlihat bahwa metode elbow dan metode silhouette menyarankan untuk menggunakan 2 cluster sedangkan gap statistics menyarankan untuk menggunakan 4 cluster.

Karena dua metode yaitu silhouette dan elbow menyarankan untuk menggunakan 2 cluster maka clustering akan dibagi menjadi **2 cluster**

# K-means clustering

```{r}
km.res <- eclust(data, "kmeans", k = 2,
                 nstart = 25, graph = FALSE)
# k-means group number of each observation
km.res$cluster
```

```{r}
fviz_cluster(km.res,  ellipse.type = "norm")
#fviz_silhouette(km.res)
```

# Hierachical clustering dengan jarak euclidean dan metode single linkage

```{r}
# dissimilarity matrix
res.dist <- dist(data, method = 'euclidean')
res.hc <- hclust(d = res.dist, method = 'single')
hc.cluster <- cutree(res.hc, k = 2)
hc.cluster
```

```{r}
fviz_dend(res.hc, rect = TRUE, show_labels = TRUE, cex = 0.5, color_labels_by_k = TRUE) 
#fviz_silhouette(res.hc)
```

# Comparing hierachical clustering and K-means clustering

```{r}
km.res$cluster
hc.cluster
```

Attaching cluster result label to data

```{r}
cluster.member1 <- data.frame(cluster = km.res$cluster)
data.c1 <- cbind(data, cluster.member1)

cluster.member2 <- data.frame(cluster = hc.cluster)
data.c2 <- cbind(data, cluster.member2)
```

# Linear discriminant analysis hasil K-Means

Dengan mengasumsi bahwa masing - masing variabel berdistribusi normal univariate.

## 1. Data preparation

### Split data to training and test set

```{r}
# Split the data into training (80%) and test set (20%)
set.seed(123)
training.samples <- data.c1$cluster %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- data.c1[training.samples, ]
test.data <- data.c1[-training.samples, ]
```

### Normalize data

```{r}
# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

```

### Compute LDA

```{r}
model <- lda(cluster~., data = train.transformed)
model
```

## 2. Make predictions

```{r}
predictions <- model %>% predict(test.data)
names(predictions)
```

## 3. Model accuracy

```{r}
mean(predictions$class==test.transformed$cluster)
```

# Linear discriminant analysis hasil Hierachical clustering

Dengan mengasumsi bahwa masing - masing variabel berdistribusi normal univariate.

## 1. Data preparation

### Split data to training and test set

```{r}
# Split the data into training (80%) and test set (20%)
set.seed(123)
training.samples <- data.c2$cluster %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data <- data.c2[training.samples, ]
test.data <- data.c2[-training.samples, ]
```

### Normalize data

```{r}
# Estimate preprocessing parameters
preproc.param <- train.data %>% 
  preProcess(method = c("center", "scale"))
# Transform the data using the estimated parameters
train.transformed <- preproc.param %>% predict(train.data)
test.transformed <- preproc.param %>% predict(test.data)

```

### Compute LDA

```{r}
model <- lda(cluster~., data = train.transformed)
model
```

## 2. Make predictions

```{r}
predictions <- model %>% predict(test.data)
names(predictions)
```

## 3. Model accuracy

```{r}
mean(predictions$class==test.transformed$cluster)
```

Dilihat dari model akurasi dapat disimpulkan bahwa metode hierachical clustering dengan jarak euclidean + metode single linkage lebih akurat dibanding metode k-means. 

\#simpan kluster

```{r}
clusterSales <- cbind(data, Cluster = km.res$cluster)
head(clusterSales)
group <- cutree(res.hc, k=2)
HierarchySales <- cbind(data, Group = as.factor(group))
head(HierarchySales)
HierarchySales %>%
  group_by(Group) %>%
  summarise_all("mean")
```

\#\#iv. Buatkan analisis diskriminan untuk memperoleh: \#a. Prosentase ketepatan klasifikasi 50 slaesman ke hasil iii.a. maupun ke hasil iii.b.

\#b. fungsi diskriminan berdasarkan hasil iii.a. maupun ke hasil iii.b.

```{r}
lda(Cluster~., data = clusterSales)
lda(Group~., data = HierarchySales)
```
